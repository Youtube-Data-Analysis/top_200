{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b097c195",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7234b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "  \n",
    "from os import path\n",
    "from requests import get\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import prepare\n",
    "import spacy\n",
    "import dexplot as dxp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1801331",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "649d33d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def acquire():\n",
    "    # use glob to get all the csv files \n",
    "    # in the folder\n",
    "    path = os.getcwd()\n",
    "    csv_files = glob.glob(os.path.join(path, \"/Users/sinao/codeup-data-science/top_200/channeloutput/*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()  \n",
    "    # loop over the list of csv files\n",
    "    for f in csv_files:\n",
    "        \n",
    "        # read the csv file\n",
    "        temp = pd.read_csv(f)\n",
    "        \n",
    "        # print the location and filename\n",
    "        temp['region']=f.split(\"\\\\\")[-1][-13:-11]\n",
    "\n",
    "        df= pd.concat([df, temp])\n",
    "\n",
    "    df['rank'] = df.index + 1\n",
    "    df['top_25'] = np.where(df['rank'] < 26, 1, 0)\n",
    "    df.description = df.description.fillna('no description')\n",
    "    df = df[df.duplicated(['video_id'], keep=False) == True].sort_values(by='rank').drop_duplicates(['video_id']).reset_index(drop=True)\n",
    "    df.region = np.where(df.region == 'IN', 'IND', df.region)\n",
    "\n",
    "\n",
    "    channel_data=pd.read_csv('combined_channel.csv')\n",
    "    channel_data = channel_data.drop(columns=['channel_id', 'country', 'view_count'])\n",
    "    channel_data = channel_data.rename(columns={'title': 'channelTitle', 'publishedAt': 'channel_age', \\\n",
    "        'sub_count':'subscribers', 'video_Count':'video_count'})\n",
    "    channel_data = channel_data.drop_duplicates(['channelTitle'])\n",
    "    channel_data.loc[1014, 'channelTitle'] = 'Дима Масленников (Pognali Show)'\n",
    "    channel_data.loc[413, 'channelTitle'] = '京口紘人 Hiroto Kyoguchi【WBA世界王者】'\n",
    "    channel_data.loc[811, 'channelTitle'] = 'finargot'\n",
    "    channel_data.loc[319, 'channelTitle'] = 'MFM - TNT Sports'\n",
    "    channel_data.loc[1969, 'channelTitle'] = 'Pátria minha'\n",
    "    \n",
    "    df = df.merge(channel_data, how='left',on='channelTitle')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0776fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6fc1b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test=pd.read_csv('combined_channel.csv')\n",
    "# test = test.drop(columns=['channel_id', 'country', 'view_count'])\n",
    "# test = test.rename(columns={'title': 'channelTitle', 'publishedAt': 'channel_age', \\\n",
    "#     'sub_count':'subscribers', 'video_Count':'video_count'})\n",
    "# test = test.drop_duplicates(['channelTitle'])\n",
    "# test.loc[1014, 'channelTitle'] = 'Дима Масленников (Pognali Show)'\n",
    "# test.loc[413, 'channelTitle'] = '京口紘人 Hiroto Kyoguchi【WBA世界王者】'\n",
    "# test.loc[811, 'channelTitle'] = 'finargot'\n",
    "# test.loc[319, 'channelTitle'] = 'MFM - TNT Sports'\n",
    "# test.loc[1969, 'channelTitle'] = 'Pátria minha'\n",
    "# df = df.merge(test, how='left',on='channelTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "438981a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2054, 37)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c69c9",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f11f6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duration(duration):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        \n",
    "    ---\n",
    "    Parameters:\n",
    "        \n",
    "    ---\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    if ('S' not in duration) & ('M' not in duration):\n",
    "        duration += '00M00S'\n",
    "    elif 'M' not in duration:\n",
    "        duration = list(duration)\n",
    "        print('stop')\n",
    "        print(list(duration))\n",
    "        duration.insert(-3, '00M') if len(duration) > 6 else duration.insert(-2, '00M')\n",
    "        duration = ''.join(duration)\n",
    "    elif 'S' not in duration:\n",
    "        duration += '00S'\n",
    "\n",
    "    if 'H' in duration:\n",
    "        duration = int(duration.split('H')[0].split('T')[1]) * 3600 + int(duration.split('H')[1].split('M')[0]) * 60 + int(duration.split('M')[1][:-1])\n",
    "    elif duration.__contains__('M'):\n",
    "        duration = int(duration.split('M')[0].split('T')[1]) * 60 + int(duration.split('M')[1][:-1])\n",
    "    else:\n",
    "        duration = int(duration[-3:-1])\n",
    "\n",
    "    return duration\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        to clean text input into function by removing duplicate words, punctuations, and other things\n",
    "    ---\n",
    "    Parameters:\n",
    "        text: a string\n",
    "    ---\n",
    "    Returns:\n",
    "        tokens: a set of words found in the input text\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    tokens = set()\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SYM', 'PUNCT', 'DET']:\n",
    "            tokens.add(token.text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        tokens.add(ent.text)\n",
    "\n",
    "    return tokens\n",
    "    \n",
    "def title_in_desc(df):\n",
    "    df['title_in_description'] = 0\n",
    "    for row in df.index:\n",
    "        title = df.iloc[row]['title']\n",
    "        description = df.iloc[row]['description']\n",
    "                    \n",
    "        if title in description:\n",
    "                df.loc[row, 'title_in_description'] = 1\n",
    "    return df\n",
    "    \n",
    "def title_in_tags (df):\n",
    "    df['title_in_tags'] = 0\n",
    "    for row in df.index:\n",
    "        title = df.iloc[row]['title']\n",
    "        tags = df.iloc[row]['tags']\n",
    "            \n",
    "    if title in tags:\n",
    "            df.loc[row, 'title_in_tags'] = 1\n",
    "    return df\n",
    "def pct_tags(df):\n",
    "    \n",
    "    df['pct_tags_in_description'] = 0\n",
    "    for row in df.index:\n",
    "        counter = 0\n",
    "        tags = df.iloc[row]['cleaned_tags']\n",
    "        description = df.iloc[row]['cleaned_desc']\n",
    "\n",
    "        for tag in tags:\n",
    "            if tag in description:\n",
    "                counter += 1\n",
    "        pct = counter/len(tags)\n",
    "        df.loc[row, 'pct_tags_in_description'] = pct\n",
    "\n",
    "    return df\n",
    "    \n",
    "def create_bank(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        to clean text input into function by removing duplicate words, punctuations, and other things\n",
    "    ---\n",
    "    Parameters:\n",
    "        text: a string\n",
    "    ---\n",
    "    Returns:\n",
    "        tokens: a set of words found in the input text\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    tokens = list()\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SYM', 'PUNCT', 'DET']:\n",
    "            tokens.append(token.text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        tokens.append(ent.text)\n",
    "\n",
    "    return tokens\n",
    "    \n",
    "def create_vaults(df):        #these vaults are to create the word clouds for each portion\n",
    "    word_vault = list()\n",
    "    for row in df.index:\n",
    "        word_vault.extend(df.iloc[row].word_bank)\n",
    "\n",
    "    top_25_words = list()\n",
    "    for row in df[df.top_25==1].index:\n",
    "        top_25_words.extend(df[df.top_25==1].iloc[row].word_bank)\n",
    "\n",
    "    outside_25_words = list()\n",
    "    for row in df[df.top_25!=1].index:\n",
    "        outside_25_words.extend(df[df.top_25!=1].iloc[row].word_bank)\n",
    "\n",
    "    return word_vault, top_25_words, outside_25_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a10107fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_youtube():\n",
    "    \n",
    "    df = acquire()\n",
    "    \n",
    "    # creates ranking for each video based off of country index\n",
    "    df.categoryId = df.categoryId.astype('object')\n",
    "    df.publishedAt = pd.to_datetime(df.publishedAt, utc=True)\n",
    "    df.trending_date = pd.to_datetime('2022-11-02', utc=True)\n",
    "    df['age']=(df.trending_date - df.publishedAt)\n",
    "    df['engagement'] = (df.likes + df.comment_count * 4 )/df.view_count\n",
    "    df['sponsored'] = np.where(df.description.str.contains('sponsor'), 1, 0)\n",
    "    df['duration'] = df['duration'].apply(lambda x:clean_duration(x))\n",
    "    #countes number of tags given to video BEFORE stripping out extraneous things\n",
    "    df['num_of_tags'] = df.tags.str.split('|').str.len()\n",
    "    #gets rid of separator\n",
    "    df.tags = df.tags.str.replace('|',\" \")\n",
    "    #import the create bank function first\n",
    "    df['word_bank']= df['description'].apply(lambda x: create_bank(x))\n",
    "    #import clean_text function first\n",
    "    df['cleaned_tags'] =  df['tags'].apply(lambda x: clean_text(x))\n",
    "    df['cleaned_desc'] = df['description'].apply(lambda x: clean_text(x))\n",
    "    df = title_in_desc(df)\n",
    "    df = title_in_tags(df)\n",
    "    df = pct_tags(df)\n",
    "    #making categorid into actual category titles\n",
    "    #all categoryId optain from youtube website\n",
    "    df.categoryId = df.categoryId.map({1: 'Film_Animation', 2: 'Autos_Vehicles',10:'Music',15: 'Pets_Animals'\n",
    "                                       ,17:'Sports',18:'Short_Movies',19:'Travel_Events',20:'Gaming',21:'Videoblogging',\n",
    "                                       22:'People_Blogs',23:'Comedy',24:'Entertainment',25:'News_Politics',\n",
    "                                       26:'Howto_Style',27: 'Education',28: 'Science_Technology', \n",
    "                                       29:'Nonprofits_Activism',30:'Movies',31:'Anime/Animation',32:'Action/Adventure',\n",
    "                                       33:'Classics',34:'Comedy',35:'Documentary',36:'Drama',37:'Family',38:'Foreign',\n",
    "                                       39:'Horror',40: 'Sci-Fi/Fantasy', 41: 'Thriller', 42:'Shorts',43:'Shows',44:'Trailers'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "af2ba041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "['P', 'T', '4', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '3', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '3', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '1', 'H', '4', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '2', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '3', 'S']\n",
      "stop\n",
      "['P', 'T', '1', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '9', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '3', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '3', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '4', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '7', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '4', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '9', 'S']\n",
      "stop\n",
      "['P', 'T', '1', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '1', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '2', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '1', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '9', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '1', 'H', '3', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '8', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '1', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '1', '6', 'S']\n",
      "stop\n",
      "['P', 'T', '2', '7', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '4', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '9', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '0', 'S']\n",
      "stop\n",
      "['P', 'T', '4', '5', 'S']\n",
      "stop\n",
      "['P', 'T', '3', '1', 'S']\n",
      "stop\n",
      "['P', 'T', '5', '7', 'S']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/9w9mh0fd73zg4jr8l_9v9h840000gn/T/ipykernel_43800/3837152935.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.tags = df.tags.str.replace('|',\" \")\n"
     ]
    }
   ],
   "source": [
    "df = prepare_youtube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8e88f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('first_stage_prepped.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "eee4da08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2019 entries, 0 to 2018\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype              \n",
      "---  ------                   --------------  -----              \n",
      " 0   video_id                 2019 non-null   object             \n",
      " 1   title                    2019 non-null   object             \n",
      " 2   publishedAt              2019 non-null   datetime64[ns, UTC]\n",
      " 3   channelTitle             2019 non-null   object             \n",
      " 4   categoryId               2019 non-null   object             \n",
      " 5   trending_date            2019 non-null   datetime64[ns, UTC]\n",
      " 6   tags                     2019 non-null   object             \n",
      " 7   view_count               2019 non-null   int64              \n",
      " 8   likes                    2019 non-null   int64              \n",
      " 9   comment_count            2019 non-null   int64              \n",
      " 10  thumbnail_link           2019 non-null   object             \n",
      " 11  comments_disabled        2019 non-null   bool               \n",
      " 12  ratings_disabled         2019 non-null   bool               \n",
      " 13  description              2019 non-null   object             \n",
      " 14  duration                 2019 non-null   int64              \n",
      " 15  captions                 2019 non-null   bool               \n",
      " 16  region                   2019 non-null   object             \n",
      " 17  rank                     2019 non-null   int64              \n",
      " 18  top_25                   2019 non-null   int64              \n",
      " 19  channel_age              2019 non-null   object             \n",
      " 20  subscribers              2019 non-null   int64              \n",
      " 21  video_count              2019 non-null   int64              \n",
      " 22  age                      2019 non-null   timedelta64[ns]    \n",
      " 23  engagement               2019 non-null   float64            \n",
      " 24  sponsored                2019 non-null   int64              \n",
      " 25  num_of_tags              2019 non-null   int64              \n",
      " 26  word_bank                2019 non-null   object             \n",
      " 27  cleaned_tags             2019 non-null   object             \n",
      " 28  cleaned_desc             2019 non-null   object             \n",
      " 29  title_in_description     2019 non-null   int64              \n",
      " 30  title_in_tags            2019 non-null   int64              \n",
      " 31  pct_tags_in_description  2019 non-null   float64            \n",
      "dtypes: bool(3), datetime64[ns, UTC](2), float64(2), int64(12), object(12), timedelta64[ns](1)\n",
      "memory usage: 543.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "20fac388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts the age category timedelta into hours .. so the videos are x hours old now \n",
    "df.age = (df.age.dt.days * 24) + (df.age.dt.seconds/3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "56831135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_lengths'] = df[\"title\"].apply(lambda x: len(x))\n",
    "df['desc_lengths'] = df[\"description\"].apply(lambda x: 0 if pd.isnull(x) else len(x))\n",
    "df['tags_length'] = df['tags'].apply(lambda x: len(x.replace('|', '')) if x != '[none]' else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a29a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.drop(columns='index', inplace=True)\n",
    "df.to_pickle('prepared.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4cf6bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prep(df):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        To create final dataframe for project usage\n",
    "    ---\n",
    "    Parameters:\n",
    "        none\n",
    "    ---\n",
    "    Returns:\n",
    "        df: final data frame for eda and modeling \n",
    "    \"\"\"\n",
    "    #calls function to import semi-prepared data frame\n",
    "    #df = prepare_youtube()\n",
    "\n",
    "    #converts the age category timedelta into hours .. so the videos are x hours old now \n",
    "    df.age = (df.age.dt.days * 24) + (df.age.dt.seconds/3600)\n",
    "\n",
    "    #converts channel_age to days\n",
    "    df.channel_age = pd.to_datetime(df.channel_age, utc=True)\n",
    "    fresh = pd.to_datetime('22.2.11', utc=True)\n",
    "    df.channel_age = df.channel_age - fresh\n",
    "    df.channel_age = df.channel_age.dt.days\n",
    "\n",
    "    #create features based on length of information within each specified column\n",
    "    df['title_lengths'] = df[\"title\"].apply(lambda x: len(x))\n",
    "    df['desc_lengths'] = df[\"description\"].apply(lambda x: 0 if pd.isnull(x) else len(x))\n",
    "    df['tags_length'] = df['tags'].apply(lambda x: len(x.replace('|', '')) if x != '[none]' else 0)\n",
    "\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    df.drop(columns='index', inplace=True)\n",
    "\n",
    "    #creates local pickle file for future usage in order to save time. else at 2+hr creation process \n",
    "    df.to_pickle('prepared.pkl')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "65ce78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_prep(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cd746e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesty = pd.read_pickle('prepared.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34032a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
