{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the list of videos contained in the csv\n",
    "df = pd.read_csv('vidz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with redundant information\n",
    "df = df.drop(columns=['comments_disabled', 'ratings_disabled' ,'thumbnail_link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categoryId = df.categoryId.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to datetime --> ppublised at, trending date, duration (timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert publishedAT to datetime column\n",
    "df.publishedAt = pd.to_datetime(df.publishedAt, utc=True)\n",
    "df.publishedAt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set date to next day in order to capture videos released at different times in different time zones\n",
    "df.trending_date = '22.28.10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert trending to datetime column\n",
    "df.trending_date = pd.to_datetime(df.trending_date, format='%y.%d.%m', utc=True)\n",
    "df.trending_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tzinfo inorder to strip time zone information from published at. \n",
    "#this makes it a \"naive\" datetime object. may want to change this approach\n",
    "# from datetime import tzinfo\n",
    "\n",
    "# df.loc[1,'publishedAt'].replace(tzinfo=None)\n",
    "#strips the timezone from each row\n",
    "# for n in range(0,200):\n",
    "#     df.loc[n,'publishedAt']= df.loc[n,'publishedAt'].replace(tzinfo=None)\n",
    "# df.loc[10, ['publishedAt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create age column. may want to give timezone info to trending date instead of removing it from pblishedAt\n",
    "df['age']=(df.trending_date - df.publishedAt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View:Like ratio that can score the video | view:comment ratio\n",
    "\n",
    "Have them all as a weighted ratio\n",
    "\n",
    "df['engagement'] = (df.likes + df.comment_count * 4 )/df.view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates engagement metric. not sure how to do weightd columns really\n",
    "#df['engagement'] = (df.view_count - df.likes) + (df.likes * 2) + (df.comment_count * 4) \n",
    "df['engagement'] = (df.likes + df.comment_count * 4 )/df.view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the video sponsored?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adds sponsored column based on appearance of word sponsored in the description\n",
    "df['sponsored'] = np.where(df.description.str.contains('sponsor'), 1, 0)\n",
    "df[df.description.str.contains('sponsored')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percent of capital letters in title \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age restricted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When we talk about subscribers we can take a look at age of channel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to drive up subscribers is a slightly separate question but we can ask it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At what point does the video view count pass the subscriber view count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s think about tags and how many words they have in common with the descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countes number of tags given to video BEFORE stripping out extraneous things\n",
    "df['num_of_tags'] = df.tags.str.split('|').str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets rid of separator\n",
    "df.tags = df.tags.str.replace('|',\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the nlp object that is going to do the heavy lifting\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses the nlp object to convert the input text into a doc\n",
    "doc = nlp(df.loc[0].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goes through tokens (words) in each doc\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates set of unique words in doc \n",
    "tokens = set()\n",
    "for token in doc:\n",
    "    tokens.add(token.text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docb = nlp(df.loc[4].description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in docb:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\")\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in docb.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "for token in docb:\n",
    "    if token.pos_ not in ['SYM', 'PUNCT', 'DET']:\n",
    "        print(token.pos_)\n",
    "        tokens.add(token.text)\n",
    "\n",
    "for ent in docb.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in docb.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" \n",
    "    Purpose:\n",
    "        to clean text input into function by removing duplicate words, punctuations, and other things\n",
    "    ---\n",
    "    Parameters:\n",
    "        text: a string\n",
    "    ---\n",
    "    Returns:\n",
    "        tokens: a set of words found in the input text\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    tokens = set()\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ not in ['SYM', 'PUNCT', 'DET']:\n",
    "            tokens.add(token.text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        tokens.add(ent.text)\n",
    "\n",
    "    return tokens\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_tags'] =  df['description'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_desc'] = df['description'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about combining the countries top 25 lists and control for duplicates. \n",
    "* This way we can classify what videos have been a top 25 video \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can target placing videos in/out of the top 25 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rank and top 25 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['top_25'] = np.where(df['rank'] < 26, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.top_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duration.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = 'PT3M45S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy.__contains__('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duration(duration):\n",
    "\n",
    "    if 'S' not in duration:\n",
    "        duration += '00S'\n",
    "\n",
    "    if duration.__contains__('M'):\n",
    "        duration = int(duration.split('M')[0].split('T')[1]) * 60 + int(duration.split('M')[1][:-1])\n",
    "    else:\n",
    "        duration = int(duration[-3:-1])\n",
    "\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df['duration'].apply(lambda x:clean_duration(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.engagement.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.top_25 == 1].engagement.plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.top_25 != 1].engagement.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "* engagement higher with top 25 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle('prepared.pkl')\n",
    "df[\"channelId\"] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.video_id.to_csv('video_ids.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df = one_df.drop_duplicates('channelTitle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_df.video_id.to_csv('video_ids.txt',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "#set working directory\n",
    "os.chdir(\"/Users/vincentbanuelos/codeup-data-science/top_200/channeloutput\")\n",
    "\n",
    "#find all csv files in the folder\n",
    "#use glob pattern matching -> extension = 'csv'\n",
    "#save result in list -> all_filenames\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "#print(all_filenames)\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "#export to csv\n",
    "combined_csv.to_csv( \"combined_channel.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translator.translate('아이들아는형님')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko\n",
      "en\n",
      "아이들아는형님\n",
      "Children who know children\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(result.src)\n",
    "print(result.dest)\n",
    "print(result.origin)\n",
    "print(result.text)\n",
    "print(result.pronunciation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>...</th>\n",
       "      <th>num_of_tags</th>\n",
       "      <th>word_bank</th>\n",
       "      <th>cleaned_tags</th>\n",
       "      <th>cleaned_desc</th>\n",
       "      <th>title_in_description</th>\n",
       "      <th>title_in_tags</th>\n",
       "      <th>pct_tags_in_description</th>\n",
       "      <th>title_lengths</th>\n",
       "      <th>desc_lengths</th>\n",
       "      <th>tags_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sWwHWK7OYJ8</td>\n",
       "      <td>[ENG][아형✪하이라이트] (여자)아이들 완전체 떴다↗ 멋짐 폭발♥ 5인 5색 토...</td>\n",
       "      <td>2022-10-29 13:26:44+00:00</td>\n",
       "      <td>아는형님 Knowingbros</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>아는 형님 형님 형님 학교 미연 민니 소연 우기 슈화 아이들 여자아이들 강호동 이수...</td>\n",
       "      <td>1098919</td>\n",
       "      <td>19090</td>\n",
       "      <td>861</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>['[', '아형', '✪', '하이라이트', '여자)아이들', '완전체', '떴다...</td>\n",
       "      <td>{'여자아이들', '아이들아는형님', 'MC', '전소연아는형님', '인기가요', ...</td>\n",
       "      <td>{'#여자아이들 #', '여자아이들', '아형', '5인', '리플레이', '수',...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>79</td>\n",
       "      <td>200</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4xl9KfUg8Lc</td>\n",
       "      <td>Pathaan | Official Teaser | Shah Rukh Khan | D...</td>\n",
       "      <td>2022-11-02 05:31:19+00:00</td>\n",
       "      <td>YRF</td>\n",
       "      <td>Film_Animation</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>shah rukh khan shahrukh khan srk shah rukh kha...</td>\n",
       "      <td>7638460</td>\n",
       "      <td>764869</td>\n",
       "      <td>75586</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>['special', 'surprise', 'for', 'very', 'specia...</td>\n",
       "      <td>{'john abraham', 'john', 'padukone', 'bollywoo...</td>\n",
       "      <td>{'YRF50', 'JollyVisual', 'Pathaan', 'Manas', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>94</td>\n",
       "      <td>1454</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vzxI6U_l72g</td>\n",
       "      <td>ヒカルくんとようやく戦えるときが来ました。</td>\n",
       "      <td>2022-10-31 10:30:10+00:00</td>\n",
       "      <td>ロードシルク</td>\n",
       "      <td>People_Blogs</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>シルクロード ロードシルク Fischer’s フィッシャーズ 個人 チャンネル 個チャン ...</td>\n",
       "      <td>613365</td>\n",
       "      <td>15756</td>\n",
       "      <td>866</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>[\"ヒカルくんhttps://www.youtube.com/channel/UCaminw...</td>\n",
       "      <td>{'大乱闘', 'ガチ', '対戦', '趣味', 'Fischer', 'サブカル', '...</td>\n",
       "      <td>{'業界の皆様・ご依頼の方々・その他ご相談がある方は、UUUMウェブサイトにある「サービス」...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>21</td>\n",
       "      <td>717</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AcznL5daQvA</td>\n",
       "      <td>Fear PIRATE CHAMPION's Spear! Clash of Clans S...</td>\n",
       "      <td>2022-11-01 08:00:04+00:00</td>\n",
       "      <td>Clash of Clans</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>clash of clans COC Clash of Clans Gameplay Cla...</td>\n",
       "      <td>2258144</td>\n",
       "      <td>44366</td>\n",
       "      <td>938</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>['Ahoy', '⚓', 'new', 'month', 'of', 'Season', ...</td>\n",
       "      <td>{'clasharama', 'challenges', 'Hall', 'Clash', ...</td>\n",
       "      <td>{'years', 'Also', 'battle', 'policy', 'http://...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>62</td>\n",
       "      <td>1874</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZYO1Z4Ajdvw</td>\n",
       "      <td>ЗА МНОЙ СЛЕДИЛИ?! ТОТ САМЫЙ ЛЕС В ЯПОНИИ! Ghos...</td>\n",
       "      <td>2022-10-31 20:54:41+00:00</td>\n",
       "      <td>Дима Масленников (Pognali Show)</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>ЗА МНОЙ СЛЕДИЛИ?! ТОТ САМЫЙ ЛЕС В ЯПОНИИ ТОТ С...</td>\n",
       "      <td>3552774</td>\n",
       "      <td>325414</td>\n",
       "      <td>14886</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>['Оформи', 'подписку', 'на', 'VK', 'Музыку', '...</td>\n",
       "      <td>{'камеру', 'МНОЙ', 'ghostbusters', 'жесть', 'п...</td>\n",
       "      <td>{'ЯПОНСКОМ', 'GhostBuster Аналитика', 'что реб...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>63</td>\n",
       "      <td>1132</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>iDBRKLjfJS4</td>\n",
       "      <td>망한 모텔 사서 한 달에 4천만원 버는 38살 사장님</td>\n",
       "      <td>2022-10-09 09:34:15+00:00</td>\n",
       "      <td>탐구생활 - 돈이 되는 삶의 이야기</td>\n",
       "      <td>People_Blogs</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>[none]</td>\n",
       "      <td>1837172</td>\n",
       "      <td>12016</td>\n",
       "      <td>1015</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['광주와', '담양에서', '호텔을', '운영하는', '여인욱', '대표님입니다탐...</td>\n",
       "      <td>{'none', '['}</td>\n",
       "      <td>{'tamgu-life@naver.com', '대표님입니다탐구생활', '여인욱', ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>U26zXbioeMs</td>\n",
       "      <td>Vete a la Versh - T5, E16: La Leyenda de Melda...</td>\n",
       "      <td>2022-10-21 21:36:39+00:00</td>\n",
       "      <td>Darkar Company Studios</td>\n",
       "      <td>Film_Animation</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>melda darkar mecoboy zelda versh nintendo mario</td>\n",
       "      <td>816003</td>\n",
       "      <td>103955</td>\n",
       "      <td>6399</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>['Gracias', 'por', 'apoyar', 'el', 'proyecto',...</td>\n",
       "      <td>{'melda', 'zelda', 'mario', 'mecoboy', 'darkar...</td>\n",
       "      <td>{'http://www.twitter.com', 'el', 'apoyar', 'mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>224</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>WRr0EDTrDx8</td>\n",
       "      <td>【プロ】バレー第1回目のゲストが本気すぎたんだけど、、、</td>\n",
       "      <td>2022-10-23 11:00:11+00:00</td>\n",
       "      <td>スカイピース</td>\n",
       "      <td>People_Blogs</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>スカイピース</td>\n",
       "      <td>1977549</td>\n",
       "      <td>48825</td>\n",
       "      <td>3060</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['\\u200b', '\\u200b@コムドット', ' ', '@中町兄妹', ' ', ...</td>\n",
       "      <td>{'スカイピース'}</td>\n",
       "      <td>{'https://www.youtube.com/channel/UC5VZjrV5x9J...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>1517</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>j-3Tpmi7CCk</td>\n",
       "      <td>Pabllo Vittar, Gloria Groove - AMEIANOITE (Off...</td>\n",
       "      <td>2022-10-21 02:59:03+00:00</td>\n",
       "      <td>Pabllo Vittar</td>\n",
       "      <td>Music</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>[none]</td>\n",
       "      <td>1529830</td>\n",
       "      <td>114260</td>\n",
       "      <td>11625</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>['Watch', 'more', 'Pabllo', 'Vittar', 'YouTube...</td>\n",
       "      <td>{'none', '['}</td>\n",
       "      <td>{'YouTube', 'vídeos', 'Suscríbete', 'sociais!h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>hgmXXsS7Eiw</td>\n",
       "      <td>Peter Fox - Zukunft Pink | REACTION</td>\n",
       "      <td>2022-10-26 08:30:15+00:00</td>\n",
       "      <td>Jay Jiggy</td>\n",
       "      <td>Music</td>\n",
       "      <td>2022-11-02 00:00:00+00:00</td>\n",
       "      <td>peter fox zukunft pink peter fox zukunft pink ...</td>\n",
       "      <td>129750</td>\n",
       "      <td>9142</td>\n",
       "      <td>494</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>['Peter', 'Fox', 'Zukunft', 'Pink', 'https://w...</td>\n",
       "      <td>{'lied', 'album', 'zukunft', 'reaction', 'neue...</td>\n",
       "      <td>{'https://music.apple.com/us/artist/jay-jiggy/...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>781</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2053 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "0     sWwHWK7OYJ8  [ENG][아형✪하이라이트] (여자)아이들 완전체 떴다↗ 멋짐 폭발♥ 5인 5색 토...   \n",
       "1     4xl9KfUg8Lc  Pathaan | Official Teaser | Shah Rukh Khan | D...   \n",
       "2     vzxI6U_l72g                              ヒカルくんとようやく戦えるときが来ました。   \n",
       "3     AcznL5daQvA  Fear PIRATE CHAMPION's Spear! Clash of Clans S...   \n",
       "4     ZYO1Z4Ajdvw  ЗА МНОЙ СЛЕДИЛИ?! ТОТ САМЫЙ ЛЕС В ЯПОНИИ! Ghos...   \n",
       "...           ...                                                ...   \n",
       "2048  iDBRKLjfJS4                      망한 모텔 사서 한 달에 4천만원 버는 38살 사장님   \n",
       "2049  U26zXbioeMs  Vete a la Versh - T5, E16: La Leyenda de Melda...   \n",
       "2050  WRr0EDTrDx8                       【プロ】バレー第1回目のゲストが本気すぎたんだけど、、、   \n",
       "2051  j-3Tpmi7CCk  Pabllo Vittar, Gloria Groove - AMEIANOITE (Off...   \n",
       "2052  hgmXXsS7Eiw                Peter Fox - Zukunft Pink | REACTION   \n",
       "\n",
       "                    publishedAt                     channelTitle  \\\n",
       "0     2022-10-29 13:26:44+00:00                 아는형님 Knowingbros   \n",
       "1     2022-11-02 05:31:19+00:00                              YRF   \n",
       "2     2022-10-31 10:30:10+00:00                           ロードシルク   \n",
       "3     2022-11-01 08:00:04+00:00                   Clash of Clans   \n",
       "4     2022-10-31 20:54:41+00:00  Дима Масленников (Pognali Show)   \n",
       "...                         ...                              ...   \n",
       "2048  2022-10-09 09:34:15+00:00              탐구생활 - 돈이 되는 삶의 이야기   \n",
       "2049  2022-10-21 21:36:39+00:00           Darkar Company Studios   \n",
       "2050  2022-10-23 11:00:11+00:00                           スカイピース   \n",
       "2051  2022-10-21 02:59:03+00:00                    Pabllo Vittar   \n",
       "2052  2022-10-26 08:30:15+00:00                        Jay Jiggy   \n",
       "\n",
       "          categoryId              trending_date  \\\n",
       "0      Entertainment  2022-11-02 00:00:00+00:00   \n",
       "1     Film_Animation  2022-11-02 00:00:00+00:00   \n",
       "2       People_Blogs  2022-11-02 00:00:00+00:00   \n",
       "3             Gaming  2022-11-02 00:00:00+00:00   \n",
       "4      Entertainment  2022-11-02 00:00:00+00:00   \n",
       "...              ...                        ...   \n",
       "2048    People_Blogs  2022-11-02 00:00:00+00:00   \n",
       "2049  Film_Animation  2022-11-02 00:00:00+00:00   \n",
       "2050    People_Blogs  2022-11-02 00:00:00+00:00   \n",
       "2051           Music  2022-11-02 00:00:00+00:00   \n",
       "2052           Music  2022-11-02 00:00:00+00:00   \n",
       "\n",
       "                                                   tags  view_count   likes  \\\n",
       "0     아는 형님 형님 형님 학교 미연 민니 소연 우기 슈화 아이들 여자아이들 강호동 이수...     1098919   19090   \n",
       "1     shah rukh khan shahrukh khan srk shah rukh kha...     7638460  764869   \n",
       "2     シルクロード ロードシルク Fischer’s フィッシャーズ 個人 チャンネル 個チャン ...      613365   15756   \n",
       "3     clash of clans COC Clash of Clans Gameplay Cla...     2258144   44366   \n",
       "4     ЗА МНОЙ СЛЕДИЛИ?! ТОТ САМЫЙ ЛЕС В ЯПОНИИ ТОТ С...     3552774  325414   \n",
       "...                                                 ...         ...     ...   \n",
       "2048                                             [none]     1837172   12016   \n",
       "2049    melda darkar mecoboy zelda versh nintendo mario      816003  103955   \n",
       "2050                                             スカイピース     1977549   48825   \n",
       "2051                                             [none]     1529830  114260   \n",
       "2052  peter fox zukunft pink peter fox zukunft pink ...      129750    9142   \n",
       "\n",
       "      comment_count  ... num_of_tags  \\\n",
       "0               861  ...          67   \n",
       "1             75586  ...          23   \n",
       "2               866  ...          32   \n",
       "3               938  ...          28   \n",
       "4             14886  ...          32   \n",
       "...             ...  ...         ...   \n",
       "2048           1015  ...           1   \n",
       "2049           6399  ...           7   \n",
       "2050           3060  ...           1   \n",
       "2051          11625  ...           1   \n",
       "2052            494  ...          12   \n",
       "\n",
       "                                              word_bank  \\\n",
       "0     ['[', '아형', '✪', '하이라이트', '여자)아이들', '완전체', '떴다...   \n",
       "1     ['special', 'surprise', 'for', 'very', 'specia...   \n",
       "2     [\"ヒカルくんhttps://www.youtube.com/channel/UCaminw...   \n",
       "3     ['Ahoy', '⚓', 'new', 'month', 'of', 'Season', ...   \n",
       "4     ['Оформи', 'подписку', 'на', 'VK', 'Музыку', '...   \n",
       "...                                                 ...   \n",
       "2048  ['광주와', '담양에서', '호텔을', '운영하는', '여인욱', '대표님입니다탐...   \n",
       "2049  ['Gracias', 'por', 'apoyar', 'el', 'proyecto',...   \n",
       "2050  ['\\u200b', '\\u200b@コムドット', ' ', '@中町兄妹', ' ', ...   \n",
       "2051  ['Watch', 'more', 'Pabllo', 'Vittar', 'YouTube...   \n",
       "2052  ['Peter', 'Fox', 'Zukunft', 'Pink', 'https://w...   \n",
       "\n",
       "                                           cleaned_tags  \\\n",
       "0     {'여자아이들', '아이들아는형님', 'MC', '전소연아는형님', '인기가요', ...   \n",
       "1     {'john abraham', 'john', 'padukone', 'bollywoo...   \n",
       "2     {'大乱闘', 'ガチ', '対戦', '趣味', 'Fischer', 'サブカル', '...   \n",
       "3     {'clasharama', 'challenges', 'Hall', 'Clash', ...   \n",
       "4     {'камеру', 'МНОЙ', 'ghostbusters', 'жесть', 'п...   \n",
       "...                                                 ...   \n",
       "2048                                      {'none', '['}   \n",
       "2049  {'melda', 'zelda', 'mario', 'mecoboy', 'darkar...   \n",
       "2050                                         {'スカイピース'}   \n",
       "2051                                      {'none', '['}   \n",
       "2052  {'lied', 'album', 'zukunft', 'reaction', 'neue...   \n",
       "\n",
       "                                           cleaned_desc  title_in_description  \\\n",
       "0     {'#여자아이들 #', '여자아이들', '아형', '5인', '리플레이', '수',...                     0   \n",
       "1     {'YRF50', 'JollyVisual', 'Pathaan', 'Manas', '...                     0   \n",
       "2     {'業界の皆様・ご依頼の方々・その他ご相談がある方は、UUUMウェブサイトにある「サービス」...                     0   \n",
       "3     {'years', 'Also', 'battle', 'policy', 'http://...                     0   \n",
       "4     {'ЯПОНСКОМ', 'GhostBuster Аналитика', 'что реб...                     0   \n",
       "...                                                 ...                   ...   \n",
       "2048  {'tamgu-life@naver.com', '대표님입니다탐구생활', '여인욱', ...                     0   \n",
       "2049  {'http://www.twitter.com', 'el', 'apoyar', 'mi...                     0   \n",
       "2050  {'https://www.youtube.com/channel/UC5VZjrV5x9J...                     0   \n",
       "2051  {'YouTube', 'vídeos', 'Suscríbete', 'sociais!h...                     0   \n",
       "2052  {'https://music.apple.com/us/artist/jay-jiggy/...                     0   \n",
       "\n",
       "     title_in_tags  pct_tags_in_description  title_lengths  desc_lengths  \\\n",
       "0                0                 0.013889             79           200   \n",
       "1                0                 0.013889             94          1454   \n",
       "2                0                 0.013889             21           717   \n",
       "3                0                 0.013889             62          1874   \n",
       "4                0                 0.013889             63          1132   \n",
       "...            ...                      ...            ...           ...   \n",
       "2048             0                 0.000000             29            54   \n",
       "2049             0                 0.000000             60           224   \n",
       "2050             0                 0.000000             28          1517   \n",
       "2051             0                 0.000000             64           352   \n",
       "2052             0                 0.000000             35           781   \n",
       "\n",
       "      tags_length  \n",
       "0             325  \n",
       "1             459  \n",
       "2             148  \n",
       "3             444  \n",
       "4             446  \n",
       "...           ...  \n",
       "2048            0  \n",
       "2049           47  \n",
       "2050            6  \n",
       "2051            0  \n",
       "2052          268  \n",
       "\n",
       "[2053 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('youtube_tren.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
