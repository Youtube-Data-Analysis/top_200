{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
<<<<<<< HEAD
    "from pprint import pprint\n",
=======
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
<<<<<<< HEAD
    "import nltk\n",
    "import spacy\n",
    "import re\n",
=======
    "import model\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
    "\n",
    "from importlib import reload\n",
    "from itertools import product\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the list of prepared pickle file contained in the csv file\n",
<<<<<<< HEAD
    "df = pd.read_pickle('prepared.pkl 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
=======
    "df = pd.read_pickle('prepared.pkl')"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "After analyzing the Top 200 trending Youtube videos, Exploration phase identified arrays of possible drivers of Top 25 trending Youtube videos. In this section, we will create a machine learning algorithm model that better and accurately predicts Top 25 trending Youtube videos and to use our takeaways and recommendations with an eye towards enabling smaller creators to produce in the mode of the top 25.\n",
    "\n",
    "Top_25 is our target variable\n",
    "\n",
    "We will use our training data to train/fit to our model and then tune the model on our validate data.\n",
    "\n",
    "We will pick our best model on accuracy.\n",
    "\n",
    "Four supervised machine learning classifications models were created in this project:\n",
    "\n",
    " - Decision Tree\n",
    " - Randon Forest\n",
    " - K-Nearest Neighbor\n",
    " - Logistic Regression "
=======
    "## Model"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Split Data\n",
    " - Split data into 3 samples of train (60%), validate(20%) and test(20%)\n",
    " - Our target variable is Top_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5721, 32), (1907, 32), (1908, 32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_train_test_split(df, target):\n",
    "    ''' \n",
    "    This function takes in a dataframe and splits data into 3 samples of train (60%), validate(20%) and test(20%).  \n",
    "    '''\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df[target])\n",
    "    train, validate = train_test_split(train, test_size=.25, random_state=123, stratify=train[target])\n",
    "    \n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = my_train_test_split(df, 'top_25')\n",
    "\n",
=======
    "After analyzing the Top 200 trending Youtube videos, Exploration phase identified arrays of possible drivers of Top 25 trending Youtube videos. In this section, we will create a machine learning algorithm model that better and accurately predicts Top 25 trending Youtube videos and to use our takeaways and recommendations with an eye towards enabling smaller creators to produce in the mode of the top 25.\n",
    "\n",
    "Top_25 is our target variable\n",
    "\n",
    "We will use our training data to train/fit to our model and then tune the model on our validate data.\n",
    "\n",
    "We will pick our best model on accuracy.\n",
    "\n",
    "Four supervised machine learning classifications models were created in this project:\n",
    "\n",
    " - Decision Tree\n",
    " - Randon Forest\n",
    " - K-Nearest Neighbor\n",
    " - Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    " - Split data into 3 samples of train (60%), validate(20%) and test(20%)\n",
    " - Our target variable is Top_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df[['categoryId','region']], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>duration</th>\n",
       "      <th>top_25</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>video_count</th>\n",
       "      <th>age</th>\n",
       "      <th>engagement</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>region_CA</th>\n",
       "      <th>region_DE</th>\n",
       "      <th>region_FR</th>\n",
       "      <th>region_GB</th>\n",
       "      <th>region_IND</th>\n",
       "      <th>region_JP</th>\n",
       "      <th>region_KR</th>\n",
       "      <th>region_MX</th>\n",
       "      <th>region_RU</th>\n",
       "      <th>region_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1098919</td>\n",
       "      <td>19090</td>\n",
       "      <td>861</td>\n",
       "      <td>1281</td>\n",
       "      <td>1</td>\n",
       "      <td>2210000</td>\n",
       "      <td>3168</td>\n",
       "      <td>82.554444</td>\n",
       "      <td>0.020506</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2217807</td>\n",
       "      <td>182434</td>\n",
       "      <td>7282</td>\n",
       "      <td>4327</td>\n",
       "      <td>1</td>\n",
       "      <td>7180000</td>\n",
       "      <td>311</td>\n",
       "      <td>29.206667</td>\n",
       "      <td>0.095392</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2258144</td>\n",
       "      <td>44366</td>\n",
       "      <td>938</td>\n",
       "      <td>24001</td>\n",
       "      <td>1</td>\n",
       "      <td>19200000</td>\n",
       "      <td>603</td>\n",
       "      <td>15.998889</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3262953</td>\n",
       "      <td>312903</td>\n",
       "      <td>14437</td>\n",
       "      <td>1862</td>\n",
       "      <td>1</td>\n",
       "      <td>15000000</td>\n",
       "      <td>408</td>\n",
       "      <td>27.088611</td>\n",
       "      <td>0.113594</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313545</td>\n",
       "      <td>4899</td>\n",
       "      <td>596</td>\n",
       "      <td>965</td>\n",
       "      <td>1</td>\n",
       "      <td>795000</td>\n",
       "      <td>2211</td>\n",
       "      <td>3.805000</td>\n",
       "      <td>0.023228</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1902762</td>\n",
       "      <td>78690</td>\n",
       "      <td>1712</td>\n",
       "      <td>1099</td>\n",
       "      <td>0</td>\n",
       "      <td>12400000</td>\n",
       "      <td>1270</td>\n",
       "      <td>270.941944</td>\n",
       "      <td>0.044955</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1976426</td>\n",
       "      <td>48816</td>\n",
       "      <td>3060</td>\n",
       "      <td>1869</td>\n",
       "      <td>0</td>\n",
       "      <td>4630000</td>\n",
       "      <td>1829</td>\n",
       "      <td>228.996944</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1529830</td>\n",
       "      <td>114260</td>\n",
       "      <td>11625</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>7720000</td>\n",
       "      <td>206</td>\n",
       "      <td>285.015833</td>\n",
       "      <td>0.105084</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>1835677</td>\n",
       "      <td>12011</td>\n",
       "      <td>1015</td>\n",
       "      <td>1191</td>\n",
       "      <td>0</td>\n",
       "      <td>321000</td>\n",
       "      <td>81</td>\n",
       "      <td>566.429167</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>430118</td>\n",
       "      <td>37109</td>\n",
       "      <td>1313</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>2570000</td>\n",
       "      <td>2608</td>\n",
       "      <td>101.242222</td>\n",
       "      <td>0.098487</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2019 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      view_count   likes  comment_count  duration  top_25  subscribers  \\\n",
       "0        1098919   19090            861      1281       1      2210000   \n",
       "1        2217807  182434           7282      4327       1      7180000   \n",
       "2        2258144   44366            938     24001       1     19200000   \n",
       "3        3262953  312903          14437      1862       1     15000000   \n",
       "4         313545    4899            596       965       1       795000   \n",
       "...          ...     ...            ...       ...     ...          ...   \n",
       "2014     1902762   78690           1712      1099       0     12400000   \n",
       "2015     1976426   48816           3060      1869       0      4630000   \n",
       "2016     1529830  114260          11625       166       0      7720000   \n",
       "2017     1835677   12011           1015      1191       0       321000   \n",
       "2018      430118   37109           1313       482       0      2570000   \n",
       "\n",
       "      video_count         age  engagement  sponsored  ...  region_CA  \\\n",
       "0            3168   82.554444    0.020506          0  ...          0   \n",
       "1             311   29.206667    0.095392          0  ...          1   \n",
       "2             603   15.998889    0.021309          0  ...          0   \n",
       "3             408   27.088611    0.113594          0  ...          0   \n",
       "4            2211    3.805000    0.023228          0  ...          0   \n",
       "...           ...         ...         ...        ...  ...        ...   \n",
       "2014         1270  270.941944    0.044955          0  ...          0   \n",
       "2015         1829  228.996944    0.030892          0  ...          0   \n",
       "2016          206  285.015833    0.105084          0  ...          0   \n",
       "2017           81  566.429167    0.008755          0  ...          0   \n",
       "2018         2608  101.242222    0.098487          0  ...          0   \n",
       "\n",
       "      region_DE  region_FR  region_GB  region_IND  region_JP  region_KR  \\\n",
       "0             0          0          0           0          0          1   \n",
       "1             0          0          0           0          0          0   \n",
       "2             1          0          0           0          0          0   \n",
       "3             0          0          0           0          0          0   \n",
       "4             0          0          0           0          1          0   \n",
       "...         ...        ...        ...         ...        ...        ...   \n",
       "2014          0          0          0           0          0          0   \n",
       "2015          0          0          0           0          1          0   \n",
       "2016          0          0          0           0          0          0   \n",
       "2017          0          0          0           0          0          1   \n",
       "2018          0          1          0           0          0          0   \n",
       "\n",
       "      region_MX  region_RU  region_US  \n",
       "0             0          0          0  \n",
       "1             0          0          0  \n",
       "2             0          0          0  \n",
       "3             0          1          0  \n",
       "4             0          0          0  \n",
       "...         ...        ...        ...  \n",
       "2014          1          0          0  \n",
       "2015          0          0          0  \n",
       "2016          0          0          0  \n",
       "2017          0          0          0  \n",
       "2018          0          0          0  \n",
       "\n",
       "[2019 rows x 41 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['categoryId','video_id','title','publishedAt','region','trending_date','tags','channelTitle',\n",
    "                'thumbnail_link','comments_disabled','ratings_disabled','ratings_disabled',\n",
    "                'ratings_disabled','description','captions','channel_age', 'rank',\n",
    "                'word_bank','cleaned_tags','cleaned_desc','title_in_description','title_in_tags'],\\\n",
    "                axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = model.my_train_test_split(df, 'top_25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1211, 41), (404, 41), (404, 41))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
    "train.shape,validate.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected features to scale into train, validate & test\n",
    "features_to_scale = ['view_count', 'likes', 'comment_count', 'duration',\\\n",
    "            'num_of_tags', 'pct_tags_in_description',\\\n",
    "            'title_lengths','desc_lengths','tags_length',\\\n",
    "            'content_rate', 'views_per_sub',\\\n",
    "            'subscribers','video_count','age','engagement','sponsored']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write function to scale data for zillow data\n",
    "def scale_data(train, validate, test, features_to_scale):\n",
    "    \"\"\"Scales the 3 data splits using MinMax Scaler. \n",
    "    Takes in train, validate, and test data splits as well as a list of the features to scale. \n",
    "    Returns dataframe with scaled counterparts on as columns\"\"\"\n",
    "    \n",
    "    \n",
    "    # Make the thing to train data only\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train[features_to_scale])\n",
    "    \n",
    "    # Fit the thing with new column names with _scaled added on\n",
    "    scaled_columns = [col+\"_scaled\" for col in features_to_scale]\n",
    "    \n",
    "    # Transform the separate datasets using the scaler learned from train\n",
    "    scaled_train = scaler.transform(train[features_to_scale])\n",
    "    scaled_validate = scaler.transform(validate[features_to_scale])\n",
    "    scaled_test = scaler.transform(test[features_to_scale])\n",
    "    \n",
    "    train_scaled = pd.concat([train, pd.DataFrame(scaled_train,index=train.index, columns = scaled_columns)],axis=1)\n",
    "    validate_scaled = pd.concat([validate, pd.DataFrame(scaled_validate,index=validate.index, columns = scaled_columns)],axis=1)\n",
    "    test_scaled = pd.concat([test, pd.DataFrame(scaled_test,index=test.index, columns = scaled_columns)],axis=1)\n",
    "\n",
    "    return train_scaled, validate_scaled, test_scaled"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate_scaled, test_scaled = model.scale_data(train, validate, test, features_to_scale)"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
<<<<<<< HEAD
    "- Select K Best\n",
    "- Uses statistical tests to determine each feature's usefulness in predicting the target variable.\n",
    "- Ranks the features and then select the K best features."
=======
    "- Select best\n",
    "- Uses statistical tests to determine each feature's usefulness in predicting the target variable.\n",
    "- Ranks the features based of highest correlation to engagement."
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected features to scale into train, validate & test\n",
    "features_to_scale = ['age','num_of_tags','duration','num_of_tags','engagement','sponsored', 'title_in_description', \n",
    "        'title_in_tags','pct_tags_in_description', 'title_lengths', 'desc_lengths','tags_length']\n",
    "train_scaled, validate_scaled, test_scaled = scale_data(train, validate, test, features_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'title', 'publishedAt', 'channelTitle', 'categoryId',\n",
       "       'trending_date', 'tags', 'view_count', 'likes', 'comment_count',\n",
       "       'thumbnail_link', 'comments_disabled', 'ratings_disabled',\n",
       "       'description', 'duration', 'captions', 'region', 'rank', 'top_25',\n",
       "       'age', 'engagement', 'sponsored', 'num_of_tags', 'word_bank',\n",
       "       'cleaned_tags', 'cleaned_desc', 'title_in_description', 'title_in_tags',\n",
       "       'pct_tags_in_description', 'title_lengths', 'desc_lengths',\n",
       "       'tags_length', 'age_scaled', 'num_of_tags_scaled', 'duration_scaled',\n",
       "       'num_of_tags_scaled', 'engagement_scaled', 'sponsored_scaled',\n",
       "       'title_in_description_scaled', 'title_in_tags_scaled',\n",
       "       'pct_tags_in_description_scaled', 'title_lengths_scaled',\n",
       "       'desc_lengths_scaled', 'tags_length_scaled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
=======
   "execution_count": 12,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [],
   "source": [
    "#X will be features\n",
    "#y will be our target variable\n",
    "#these features have high correlation to top_25 videos\n",
<<<<<<< HEAD
    "\n",
    "scaled_features = ['age_scaled', 'num_of_tags_scaled','duration_scaled', 'num_of_tags_scaled',\n",
    "       'engagement_scaled', 'sponsored_scaled', 'title_in_description', 'title_in_tags',\n",
    "       'pct_tags_in_description', 'title_lengths', 'desc_lengths',\n",
    "    'tags_length']\n",
    "X_train = train_scaled[scaled_features]\n",
    "y_train = train_scaled.top_25\n",
    "X_validate = validate_scaled[scaled_features]\n",
    "y_validate = validate_scaled.top_25\n",
    "X_test = test_scaled[scaled_features]\n",
    "y_test= test_scaled.top_25"
=======
    "X_train, y_train, X_validate, y_validate, X_test, y_test = model.getting_(train_scaled,validate_scaled,test_scaled)"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Prediction and Accuracy\n",
    "- Baseline prediction is a benchmark. It predicts the most prevelant class in the train data. We compare our model and want it to be better than the baseline prediction."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 13,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0    4986\n",
       "1     735\n",
       "Name: top_25, dtype: int64"
      ]
     },
     "execution_count": 9,
=======
       "0    987\n",
       "1    224\n",
       "Name: top_25, dtype: int64"
      ]
     },
     "execution_count": 13,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at values of target variable top_25\n",
    "# baseline prediction: the most prevalent class in training dataset(the mode)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 14,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Top_25 videos baseline accuracy is: 0.8715259570005244\n"
=======
      "Top_25 videos baseline accuracy is: 0.815028901734104\n"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
=======
    "#Formulate baseline accuracy\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
    "baseline_accuracy = (y_train == 0).mean()\n",
    "print('Top_25 videos baseline accuracy is:', baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model on Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_scores = model.run_decision_tree_models(X_train, y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_validate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
       "      <td>0.871526</td>\n",
       "      <td>0.871526</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.889879</td>\n",
       "      <td>0.883062</td>\n",
       "      <td>0.006817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.891802</td>\n",
       "      <td>0.889879</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.906485</td>\n",
       "      <td>0.896696</td>\n",
       "      <td>0.009788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.916973</td>\n",
       "      <td>0.909806</td>\n",
       "      <td>0.007167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.933228</td>\n",
       "      <td>0.918721</td>\n",
       "      <td>0.014508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.946163</td>\n",
       "      <td>0.930781</td>\n",
       "      <td>0.015382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.956301</td>\n",
       "      <td>0.930781</td>\n",
       "      <td>0.025520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.969761</td>\n",
       "      <td>0.939696</td>\n",
       "      <td>0.030065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.978850</td>\n",
       "      <td>0.937598</td>\n",
       "      <td>0.041252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.987590</td>\n",
       "      <td>0.940220</td>\n",
       "      <td>0.047369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.940745</td>\n",
       "      <td>0.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.996155</td>\n",
       "      <td>0.942842</td>\n",
       "      <td>0.053312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.997902</td>\n",
       "      <td>0.946513</td>\n",
       "      <td>0.051390</td>\n",
=======
       "      <td>5</td>\n",
       "      <td>0.922378</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.046141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.067610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.958712</td>\n",
       "      <td>0.873762</td>\n",
       "      <td>0.084949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.971098</td>\n",
       "      <td>0.878713</td>\n",
       "      <td>0.092385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.986788</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.125402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.995045</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.123758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0.997523</td>\n",
       "      <td>0.856436</td>\n",
       "      <td>0.141087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.138614</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "     i  accuracy_train  accuracy_validate  difference\n",
       "0    1        0.871526           0.871526    0.000000\n",
       "1    2        0.889879           0.883062    0.006817\n",
       "2    3        0.891802           0.889879    0.001923\n",
       "3    4        0.906485           0.896696    0.009788\n",
       "4    5        0.916973           0.909806    0.007167\n",
       "5    6        0.933228           0.918721    0.014508\n",
       "6    7        0.946163           0.930781    0.015382\n",
       "7    8        0.956301           0.930781    0.025520\n",
       "8    9        0.969761           0.939696    0.030065\n",
       "9   10        0.978850           0.937598    0.041252\n",
       "10  11        0.987590           0.940220    0.047369\n",
       "11  12        0.992484           0.940745    0.051739\n",
       "12  13        0.996155           0.942842    0.053312\n",
       "13  14        0.997902           0.946513    0.051390"
      ]
     },
     "execution_count": 11,
=======
       "    i  accuracy_train  accuracy_validate  difference\n",
       "0   5        0.922378           0.876238    0.046141\n",
       "1   6        0.943848           0.876238    0.067610\n",
       "2   7        0.958712           0.873762    0.084949\n",
       "3   8        0.971098           0.878713    0.092385\n",
       "4   9        0.986788           0.861386    0.125402\n",
       "5  10        0.995045           0.871287    0.123758\n",
       "6  11        0.997523           0.856436    0.141087\n",
       "7  12        1.000000           0.861386    0.138614\n",
       "8  13        1.000000           0.861386    0.138614\n",
       "9  14        1.000000           0.861386    0.138614"
      ]
     },
     "execution_count": 16,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "#loop the model with changing max depth only\n",
    "model_scores = []\n",
    "for i in range(1,15):\n",
    "    model = DecisionTreeClassifier(max_depth=i, random_state =123)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    accuracy_train = model.score(X_train,y_train)\n",
    "    accuracy_validate = model.score(X_validate,y_validate)\n",
    "    difference = accuracy_train-accuracy_validate\n",
    "    output = {\"i\":i, \"accuracy_train\":accuracy_train,\"accuracy_validate\":accuracy_validate,\"difference\":difference}\n",
    "    model_scores.append(output)\n",
    "df = pd.DataFrame(model_scores)\n",
    "df"
=======
    "dtc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_scores.to_csv('dtc_scores_tab.csv')"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with maximun sample leaf 14 @ 94% accuracy on validate is the best"
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with maximun sample leaf 8 @ 87% accuracy on validate is the best"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/top_200/model.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = model.run_random_forest_models(X_train, y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>min_sample_leaf</th>\n",
=======
       "      <th>max_depth</th>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_validate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>1</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.944415</td>\n",
       "      <td>0.055235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.985842</td>\n",
       "      <td>0.937598</td>\n",
       "      <td>0.048243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.931306</td>\n",
       "      <td>0.046146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.971159</td>\n",
       "      <td>0.930257</td>\n",
       "      <td>0.040902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.965391</td>\n",
       "      <td>0.928684</td>\n",
       "      <td>0.036707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.959622</td>\n",
       "      <td>0.924489</td>\n",
       "      <td>0.035134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.957001</td>\n",
       "      <td>0.921867</td>\n",
       "      <td>0.035134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.950358</td>\n",
       "      <td>0.920818</td>\n",
       "      <td>0.029540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.947736</td>\n",
       "      <td>0.918196</td>\n",
       "      <td>0.029540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.945639</td>\n",
       "      <td>0.919245</td>\n",
       "      <td>0.026394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.942318</td>\n",
       "      <td>0.917147</td>\n",
       "      <td>0.025170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.939871</td>\n",
       "      <td>0.916623</td>\n",
       "      <td>0.023248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.936200</td>\n",
       "      <td>0.905611</td>\n",
       "      <td>0.030589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.936200</td>\n",
       "      <td>0.911904</td>\n",
       "      <td>0.024296</td>\n",
=======
       "      <td>10</td>\n",
       "      <td>0.975227</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.098989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0.984310</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.108073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.112202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.873762</td>\n",
       "      <td>0.114677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.883663</td>\n",
       "      <td>0.104776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.991742</td>\n",
       "      <td>0.886139</td>\n",
       "      <td>0.105604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0.990091</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.108903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>0.992568</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.111380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>0.990091</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.108903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.990091</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.108903</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "    min_sample_leaf  accuracy_train  accuracy_validate  difference\n",
       "0                 1        0.999650           0.944415    0.055235\n",
       "1                 2        0.985842           0.937598    0.048243\n",
       "2                 3        0.977451           0.931306    0.046146\n",
       "3                 4        0.971159           0.930257    0.040902\n",
       "4                 5        0.965391           0.928684    0.036707\n",
       "5                 6        0.959622           0.924489    0.035134\n",
       "6                 7        0.957001           0.921867    0.035134\n",
       "7                 8        0.950358           0.920818    0.029540\n",
       "8                 9        0.947736           0.918196    0.029540\n",
       "9                10        0.945639           0.919245    0.026394\n",
       "10               11        0.942318           0.917147    0.025170\n",
       "11               12        0.939871           0.916623    0.023248\n",
       "12               13        0.936200           0.905611    0.030589\n",
       "13               14        0.936200           0.911904    0.024296"
      ]
     },
     "execution_count": 13,
=======
       "   max_depth  accuracy_train  accuracy_validate  difference\n",
       "0         10        0.975227           0.876238    0.098989\n",
       "1         11        0.984310           0.876238    0.108073\n",
       "2         12        0.988439           0.876238    0.112202\n",
       "3         13        0.988439           0.873762    0.114677\n",
       "4         14        0.988439           0.883663    0.104776\n",
       "5         15        0.991742           0.886139    0.105604\n",
       "6         16        0.990091           0.881188    0.108903\n",
       "7         17        0.992568           0.881188    0.111380\n",
       "8         18        0.990091           0.881188    0.108903\n",
       "9         19        0.990091           0.881188    0.108903"
      ]
     },
     "execution_count": 22,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "#model with tuning min sample leaf only\n",
    "model_scores = []\n",
    "\n",
    "for i in range(1,15):\n",
    "\n",
    "    model = RandomForestClassifier(min_samples_leaf= i,random_state=123)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    accuracy_train = model.score(X_train,y_train)\n",
    "    accuracy_validate = model.score(X_validate,y_validate)\n",
    "    difference = accuracy_train-accuracy_validate\n",
    "    output = {\"min_sample_leaf\":i, \"accuracy_train\":accuracy_train,\"accuracy_validate\":accuracy_validate,\"difference\":difference}\n",
    "    model_scores.append(output)\n",
    "df = pd.DataFrame(model_scores)\n",
    "df"
=======
    "rf_scores"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest model with minimun sample leaf 1 @ 94% accuracy on validate is the best\n",
    "# need a high range to get the best, so let's try max!"
=======
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores.to_csv('rf_scores_tab.csv')"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with maximun sample leaf 15 @ 88% accuracy on validate is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/top_200/model.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores = model.run_kneighbors_models(X_train, y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
<<<<<<< HEAD
       "      <th>max_depth</th>\n",
=======
       "      <th>k</th>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_validate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
<<<<<<< HEAD
       "      <td>0.871526</td>\n",
       "      <td>0.871526</td>\n",
       "      <td>0.000000</td>\n",
=======
       "      <td>1.000000</td>\n",
       "      <td>0.690594</td>\n",
       "      <td>0.309406</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
<<<<<<< HEAD
       "      <td>0.871526</td>\n",
       "      <td>0.871526</td>\n",
       "      <td>0.000000</td>\n",
=======
       "      <td>0.853840</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.041959</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
<<<<<<< HEAD
       "      <td>0.872400</td>\n",
       "      <td>0.871526</td>\n",
       "      <td>0.000874</td>\n",
=======
       "      <td>0.853014</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.070836</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
<<<<<<< HEAD
       "      <td>0.877294</td>\n",
       "      <td>0.876770</td>\n",
       "      <td>0.000524</td>\n",
=======
       "      <td>0.830718</td>\n",
       "      <td>0.809406</td>\n",
       "      <td>0.021312</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
<<<<<<< HEAD
       "      <td>0.898969</td>\n",
       "      <td>0.889355</td>\n",
       "      <td>0.009614</td>\n",
=======
       "      <td>0.831544</td>\n",
       "      <td>0.806931</td>\n",
       "      <td>0.024613</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
<<<<<<< HEAD
       "      <td>0.915050</td>\n",
       "      <td>0.897745</td>\n",
       "      <td>0.017305</td>\n",
=======
       "      <td>0.826590</td>\n",
       "      <td>0.806931</td>\n",
       "      <td>0.019659</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
<<<<<<< HEAD
       "      <td>0.928509</td>\n",
       "      <td>0.905087</td>\n",
       "      <td>0.023422</td>\n",
=======
       "      <td>0.824112</td>\n",
       "      <td>0.804455</td>\n",
       "      <td>0.019657</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
<<<<<<< HEAD
       "      <td>0.938298</td>\n",
       "      <td>0.909282</td>\n",
       "      <td>0.029016</td>\n",
=======
       "      <td>0.820809</td>\n",
       "      <td>0.809406</td>\n",
       "      <td>0.011403</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
<<<<<<< HEAD
       "      <td>0.949135</td>\n",
       "      <td>0.915574</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.961545</td>\n",
       "      <td>0.923964</td>\n",
       "      <td>0.037581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.974480</td>\n",
       "      <td>0.930257</td>\n",
       "      <td>0.044223</td>\n",
=======
       "      <td>0.819158</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.017178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  accuracy_train  accuracy_validate  difference\n",
       "0  1        1.000000           0.690594    0.309406\n",
       "1  2        0.853840           0.811881    0.041959\n",
       "2  3        0.853014           0.782178    0.070836\n",
       "3  4        0.830718           0.809406    0.021312\n",
       "4  5        0.831544           0.806931    0.024613\n",
       "5  6        0.826590           0.806931    0.019659\n",
       "6  7        0.824112           0.804455    0.019657\n",
       "7  8        0.820809           0.809406    0.011403\n",
       "8  9        0.819158           0.801980    0.017178"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores.to_csv('knn_scores_tab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN model with minimun sample leaf 2 @ 81% accuracy on validate is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model' from '/Users/sinao/codeup-data-science/top_200/model.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores = model.run_logistic_reg_models(X_train, y_train, X_validate, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_validate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.814203</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>-0.007579</td>\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "    max_depth  accuracy_train  accuracy_validate  difference\n",
       "0           1        0.871526           0.871526    0.000000\n",
       "1           2        0.871526           0.871526    0.000000\n",
       "2           3        0.872400           0.871526    0.000874\n",
       "3           4        0.877294           0.876770    0.000524\n",
       "4           5        0.898969           0.889355    0.009614\n",
       "5           6        0.915050           0.897745    0.017305\n",
       "6           7        0.928509           0.905087    0.023422\n",
       "7           8        0.938298           0.909282    0.029016\n",
       "8           9        0.949135           0.915574    0.033561\n",
       "9          10        0.961545           0.923964    0.037581\n",
       "10         11        0.974480           0.930257    0.044223"
      ]
     },
     "execution_count": 15,
=======
       "   accuracy_train  accuracy_validate  difference\n",
       "0        0.814203           0.821782   -0.007579"
      ]
     },
     "execution_count": 32,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model_scores = []\n",
    "\n",
    "for i in range(1,12):\n",
    "\n",
    "    model = RandomForestClassifier(max_depth = i,random_state=123)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    accuracy_train = model.score(X_train,y_train)\n",
    "    accuracy_validate = model.score(X_validate,y_validate)\n",
    "    difference = accuracy_train-accuracy_validate\n",
    "    output = {\"max_depth\":i, \"accuracy_train\":accuracy_train,\"accuracy_validate\":accuracy_validate,\"difference\":difference}\n",
    "    model_scores.append(output)\n",
    "df = pd.DataFrame(model_scores)\n",
    "df"
=======
    "lr_scores"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with maximun sample leaf 11 @ 93% accuracy on validate is the best"
=======
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores.to_csv('lr_scores_tab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression has 82% accuracy on validate"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## KNeighborsClassifier"
=======
    "## Test Model"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 35,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_validate</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>0.930257</td>\n",
       "      <td>0.069393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.967313</td>\n",
       "      <td>0.901940</td>\n",
       "      <td>0.065373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.957874</td>\n",
       "      <td>0.878867</td>\n",
       "      <td>0.079007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.931481</td>\n",
       "      <td>0.888831</td>\n",
       "      <td>0.042650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.923615</td>\n",
       "      <td>0.879392</td>\n",
       "      <td>0.044223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.911729</td>\n",
       "      <td>0.878343</td>\n",
       "      <td>0.033386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.908058</td>\n",
       "      <td>0.869428</td>\n",
       "      <td>0.038630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.897396</td>\n",
       "      <td>0.874148</td>\n",
       "      <td>0.023248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.894948</td>\n",
       "      <td>0.868380</td>\n",
       "      <td>0.026569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  accuracy_train  accuracy_validate  difference\n",
       "0  1        0.999650           0.930257    0.069393\n",
       "1  2        0.967313           0.901940    0.065373\n",
       "2  3        0.957874           0.878867    0.079007\n",
       "3  4        0.931481           0.888831    0.042650\n",
       "4  5        0.923615           0.879392    0.044223\n",
       "5  6        0.911729           0.878343    0.033386\n",
       "6  7        0.908058           0.869428    0.038630\n",
       "7  8        0.897396           0.874148    0.023248\n",
       "8  9        0.894948           0.868380    0.026569"
      ]
     },
     "execution_count": 17,
=======
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 35,
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "#For loop for KNN \n",
    "empty_model = []\n",
    "for k in range(1,10):\n",
    "    model = KNeighborsClassifier(n_neighbors = k, weights = \"uniform\")\n",
    "    model=model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    accuracy_train = model.score(X_train,y_train)\n",
    "    accuracy_validate = model.score(X_validate,y_validate)\n",
    "    difference = accuracy_train-accuracy_validate\n",
    "    output = {\"k\":k, \"accuracy_train\":accuracy_train,\"accuracy_validate\":accuracy_validate,\"difference\":difference}\n",
    "    \n",
    "    \n",
    "    empty_model.append(output)\n",
    "\n",
    "df = pd.DataFrame(empty_model)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN model with minimun sample leaf 1 @ 93% accuracy on validate is the best"
=======
    "model.run__on_test(X_train, y_train, X_test, y_test)"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.8711763677678728,\n",
       " 'accuracy_validate': 0.8715259570005244,\n",
       " 'difference': -0.0003495892326516037}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C = .1, random_state=123)\n",
    "model=model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_train)\n",
    "accuracy_train = model.score(X_train,y_train)\n",
    "accuracy_validate = model.score(X_validate,y_validate)\n",
    "difference = accuracy_train-accuracy_validate\n",
    "output = { \"accuracy_train\":accuracy_train,\"accuracy_validate\":accuracy_validate,\"difference\":difference}\n",
    "    \n",
    "output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression has 87% accuracy on validate"
=======
    "## Test Takeaways"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create, fit, use, model information to model_features dfram\n",
    "model = DecisionTreeClassifier(max_depth=14, random_state=123)\n",
    "#features to be used\n",
    "\n",
    "scaled_features = ['age_scaled', 'num_of_tags_scaled','duration_scaled', 'num_of_tags_scaled',\n",
    "       'engagement_scaled', 'sponsored_scaled', 'title_in_description', 'title_in_tags',\n",
    "       'pct_tags_in_description', 'title_lengths', 'desc_lengths',\n",
    "    'tags_length']\n",
    "#fit model\n",
    "model.fit(X_train, y_train)\n",
    "#score model to add to model description dataframe\n",
    "score = model.score(X_test, y_test).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941\n"
     ]
    }
   ],
   "source": [
    "print (score)"
=======
    "- Random Forest model performed best on validate data with 88% accuracy, so we will use it on test data.\n",
    "- The test does not show 88% but instead 84% because of the unseen data. "
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "## Test Takeaways"
=======
    "## Modeling Takeaways"
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "- Decision Tree Classifier model performed best on validate data with 94% accuracy, so we will use it on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All models had roughly almost the same accuracy for train and validate sets.\n",
    "- Logistic Regression model performed the worst on out-of-sample data.\n",
    "- The best performing model is Decision Tree Classifier.\n",
    "- However, from the above model analysis we can see that the highest accuracy is achieved by Decision Tree. It performs better than baseline by about 7%.\n",
=======
    "- Random Forest and Decision Tree models had roughly almost the same accuracy for train and validate sets.\n",
    "- KNeighbors Classifier and Logistic Regression model performed the worst on out-of-sample data.\n",
    "- The best performing model is Random Forest Classifier.\n",
    "- However, from the above model analysis we can see that the highest accuracy is achieved by Random Forest. It performs better than baseline by about 7%.\n",
>>>>>>> ddb65c321963dbd6bc7cfedab05785846585ef21
    "\n",
    "- While this is an improvement there is still room for improvement in future iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
